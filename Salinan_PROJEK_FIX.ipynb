{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ugPvWVPtCUhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQUulk3G-vEP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 1. Menyiapkan Augmentasi Data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 2. Memuat Data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/SC/ribuan/latih',  # Path data pelatihan\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,  # Sesuaikan batch size\n",
        "    class_mode='sparse',\n",
        "    shuffle=True  # Data dilatih dengan shuffle\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/SC/ribuan/validasi',  # Path data validasi\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,  # Sesuaikan batch size\n",
        "    class_mode='sparse',\n",
        "    shuffle=False  # Validasi tidak perlu shuffle\n",
        ")\n",
        "\n",
        "# 3. Membuat Model dengan Transfer Learning (MobileNetV2)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Membekukan beberapa layer pertama base model (misalnya sampai layer ke-100)\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Membebaskan beberapa layer terakhir untuk fine-tuning\n",
        "for layer in base_model.layers[100:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Membangun model dengan lapisan tambahan\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)  # Tambahkan regularisasi L2\n",
        "x = Dropout(0.5)(x)  # Regularisasi dropout\n",
        "x = Dense(10, activation='softmax')(x)  # Sesuaikan dengan jumlah kelas\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# 4. Kompilasi Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Menampilkan ringkasan model\n",
        "model.summary()\n",
        "\n",
        "# 5. Melatih Model\n",
        "# 5. Melatih Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=10  # Jumlah epoch tetap\n",
        ")\n",
        "\n",
        "# Menyimpan Model\n",
        "# Menentukan versi model\n",
        "version = 7\n",
        "model_filename = f'model_v{version}.h5'\n",
        "\n",
        "# Menyimpan model\n",
        "model.save(model_filename)\n",
        "print(f\"Model disimpan ke: {model_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# 1. Mengevaluasi Model dengan Dataset Validasi\n",
        "val_loss, val_accuracy = model.evaluate(validation_generator, verbose=1)\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# 2. Mendapatkan Prediksi dan Label Asli\n",
        "y_true = validation_generator.classes  # Label sebenarnya\n",
        "y_pred_prob = model.predict(validation_generator, verbose=1)  # Prediksi probabilitas\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)  # Mengambil kelas dengan probabilitas tertinggi\n",
        "\n",
        "# 3. Menghitung Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# 4. Menampilkan Confusion Matrix Berwarna\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=validation_generator.class_indices.keys(), yticklabels=validation_generator.class_indices.keys())\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# 5. Menghasilkan Laporan Klasifikasi (Precision, Recall, F1 Score)\n",
        "target_names = list(validation_generator.class_indices.keys())  # Nama kelas\n",
        "report = classification_report(y_true, y_pred, target_names=target_names, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# 6. Menghitung Error Rate\n",
        "error_rate = 1 - val_accuracy\n",
        "print(f\"Error Rate: {error_rate:.4f}\")"
      ],
      "metadata": {
        "id": "qFiQBYN2JDep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import FileUpload, Image, VBox\n",
        "from PIL import Image as PILImage\n",
        "import io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Daftar kelas yang sesuai dengan model Anda\n",
        "class_names = ['bat', 'butterfly', 'cat', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'squirrel', 'tiger']\n",
        "\n",
        "# Load model (gunakan model Anda sendiri)\n",
        "model = tf.keras.models.load_model('/content/model_v7.h5')\n",
        "\n",
        "# Membuat widget untuk mengupload file\n",
        "upload = FileUpload(accept='image/*', multiple=False)\n",
        "\n",
        "# Membuat widget Image untuk menampilkan gambar dengan ukuran tampilan yang disesuaikan\n",
        "image_widget = Image()\n",
        "\n",
        "# Fungsi untuk memproses gambar setelah diupload\n",
        "def process_uploaded_image(change):\n",
        "    # Mendapatkan file yang diupload\n",
        "    img_data = next(iter(upload.value.values()))['content']\n",
        "\n",
        "    # Membuka gambar dengan PIL\n",
        "    img = PILImage.open(io.BytesIO(img_data))\n",
        "\n",
        "    # Menampilkan gambar yang diupload pada widget\n",
        "    img_resized = img.resize((400, 400))  # Mengubah ukuran gambar sesuai keinginan\n",
        "    img_bytes = io.BytesIO()\n",
        "    img_resized.save(img_bytes, format='PNG')\n",
        "    img_bytes.seek(0)\n",
        "\n",
        "    image_widget.value = img_bytes.read()  # Update widget image dengan gambar yang sudah diubah ukurannya\n",
        "    image_widget.width = 300  # Atur lebar tampilan gambar\n",
        "    image_widget.height = 300  # Atur tinggi tampilan gambar\n",
        "\n",
        "    # Mengubah ukuran gambar sesuai input model (224x224)\n",
        "    img_resized_for_model = img.resize((224, 224))\n",
        "\n",
        "    # Mengubah gambar menjadi array numpy\n",
        "    img_array = np.array(img_resized_for_model)\n",
        "\n",
        "    # Menambah dimensi batch\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Normalisasi (sesuai dengan model yang digunakan)\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Melakukan prediksi\n",
        "    classes = model.predict(img_array)\n",
        "\n",
        "    # Mengidentifikasi kelas berdasarkan prediksi\n",
        "    predicted_class = np.argmax(classes, axis=1)\n",
        "\n",
        "    # Menampilkan nama kelas prediksi\n",
        "    predicted_class_name = class_names[predicted_class[0]]\n",
        "    print(f'Predicted Class: {predicted_class_name}')\n",
        "\n",
        "# Menyambungkan fungsi dengan upload event\n",
        "upload.observe(process_uploaded_image, names='value')\n",
        "\n",
        "# Tampilkan widget upload dan gambar\n",
        "display(VBox([upload, image_widget]))"
      ],
      "metadata": {
        "id": "XSW8DG-DJGan"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}